{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPeExS3URkzdn8KbUXTKas9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EyeofaThous/AAE590/blob/main/AAE590Lecture19tbranno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmMDm1llNzsh",
        "outputId": "29a91259-0d5b-4df6-f62e-86ff71d40146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mnist==0.2.2 (from -r requirements.txt (line 1))\n",
            "  Using cached mnist-0.2.2-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting numpy==1.16.3 (from -r requirements.txt (line 2))\n",
            "  Using cached numpy-1.16.3.zip (5.1 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting keras==2.2.4 (from -r requirements.txt (line 3))\n",
            "  Using cached Keras-2.2.4-py2.py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.11/dist-packages (from keras==2.2.4->-r requirements.txt (line 3)) (1.14.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from keras==2.2.4->-r requirements.txt (line 3)) (1.17.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from keras==2.2.4->-r requirements.txt (line 3)) (6.0.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras==2.2.4->-r requirements.txt (line 3)) (3.13.0)\n",
            "Collecting keras-applications>=1.0.6 (from keras==2.2.4->-r requirements.txt (line 3))\n",
            "  Using cached Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting keras-preprocessing>=1.0.5 (from keras==2.2.4->-r requirements.txt (line 3))\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting scipy>=0.14 (from keras==2.2.4->-r requirements.txt (line 3))\n",
            "  Using cached scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Using cached scipy-1.15.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Using cached scipy-1.15.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "  Using cached scipy-1.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Using cached scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Using cached scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Using cached scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "INFO: pip is still looking at multiple versions of scipy to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Using cached scipy-1.11.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "  Using cached scipy-1.11.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
            "  Using cached scipy-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (59 kB)\n",
            "  Using cached scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached scipy-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "  Using cached scipy-1.9.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "  Using cached scipy-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "  Using cached scipy-1.9.1.tar.gz (42.0 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 427, in resolve\n",
            "    failure_causes = self._attempt_to_pin_criterion(name)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 237, in _attempt_to_pin_criterion\n",
            "    for candidate in criterion.candidates:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 88, in _iter_built_with_prepended\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n",
            "    self._install_build_reqs(finder)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n",
            "    build_reqs = self._get_build_requires_wheel()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n",
            "    return backend.get_requires_for_build_wheel()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/misc.py\", line 709, in get_requires_for_build_wheel\n",
            "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 166, in get_requires_for_build_wheel\n",
            "    return self._call_hook('get_requires_for_build_wheel', {\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 311, in _call_hook\n",
            "    self._subprocess_runner(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/subprocess.py\", line 237, in runner\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1477, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1634, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1644, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1706, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 978, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.11/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1230, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 953, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 695, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/logging/__init__.py\", line 645, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 728, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 413, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 350, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/traceback.py\", line 364, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python cnn.py\n",
        "python cnn_keras.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "VEBG3JPsXVpw",
        "outputId": "08afb2b5-7409-46ce-9833-56d585fe6861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-10-fe2ef34fea0f>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-fe2ef34fea0f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python cnn.py\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "leX0_KgzKF3z",
        "outputId": "69776b76-9c55-4b66-f703-e29e20e84737"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'conv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cb58932b7fb1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConv3x3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaxpool\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaxPool2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'conv'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import mnist\n",
        "import numpy as np\n",
        "from conv import Conv3x3\n",
        "from maxpool import MaxPool2\n",
        "from softmax import Softmax\n",
        "\n",
        "# We only use the first 1k examples of each set in the interest of time.\n",
        "# Feel free to change this if you want.\n",
        "train_images = mnist.train_images()[:1000]\n",
        "train_labels = mnist.train_labels()[:1000]\n",
        "test_images = mnist.test_images()[:1000]\n",
        "test_labels = mnist.test_labels()[:1000]\n",
        "\n",
        "conv = Conv3x3(8)                  # 28x28x1 -> 26x26x8\n",
        "pool = MaxPool2()                  # 26x26x8 -> 13x13x8\n",
        "softmax = Softmax(13 * 13 * 8, 10) # 13x13x8 -> 10\n",
        "\n",
        "def forward(image, label):\n",
        "  '''\n",
        "  Completes a forward pass of the CNN and calculates the accuracy and\n",
        "  cross-entropy loss.\n",
        "  - image is a 2d numpy array\n",
        "  - label is a digit\n",
        "  '''\n",
        "  # We transform the image from [0, 255] to [-0.5, 0.5] to make it easier\n",
        "  # to work with. This is standard practice.\n",
        "  out = conv.forward((image / 255) - 0.5)\n",
        "  out = pool.forward(out)\n",
        "  out = softmax.forward(out)\n",
        "\n",
        "  # Calculate cross-entropy loss and accuracy. np.log() is the natural log.\n",
        "  loss = -np.log(out[label])\n",
        "  acc = 1 if np.argmax(out) == label else 0\n",
        "\n",
        "  return out, loss, acc\n",
        "\n",
        "def train(im, label, lr=.005):\n",
        "  '''\n",
        "  Completes a full training step on the given image and label.\n",
        "  Returns the cross-entropy loss and accuracy.\n",
        "  - image is a 2d numpy array\n",
        "  - label is a digit\n",
        "  - lr is the learning rate\n",
        "  '''\n",
        "  # Forward\n",
        "  out, loss, acc = forward(im, label)\n",
        "\n",
        "  # Calculate initial gradient\n",
        "  gradient = np.zeros(10)\n",
        "  gradient[label] = -1 / out[label]\n",
        "\n",
        "  # Backprop\n",
        "  gradient = softmax.backprop(gradient, lr)\n",
        "  gradient = pool.backprop(gradient)\n",
        "  gradient = conv.backprop(gradient, lr)\n",
        "\n",
        "  return loss, acc\n",
        "\n",
        "print('MNIST CNN initialized!')\n",
        "\n",
        "# Train the CNN for 3 epochs\n",
        "for epoch in range(3):\n",
        "  print('--- Epoch %d ---' % (epoch + 1))\n",
        "\n",
        "  # Shuffle the training data\n",
        "  permutation = np.random.permutation(len(train_images))\n",
        "  train_images = train_images[permutation]\n",
        "  train_labels = train_labels[permutation]\n",
        "\n",
        "  # Train!\n",
        "  loss = 0\n",
        "  num_correct = 0\n",
        "  for i, (im, label) in enumerate(zip(train_images, train_labels)):\n",
        "    if i % 100 == 99:\n",
        "      print(\n",
        "        '[Step %d] Past 100 steps: Average Loss %.3f | Accuracy: %d%%' %\n",
        "        (i + 1, loss / 100, num_correct)\n",
        "      )\n",
        "      loss = 0\n",
        "      num_correct = 0\n",
        "\n",
        "    l, acc = train(im, label)\n",
        "    loss += l\n",
        "    num_correct += acc\n",
        "\n",
        "# Test the CNN\n",
        "print('\\n--- Testing the CNN ---')\n",
        "loss = 0\n",
        "num_correct = 0\n",
        "for im, label in zip(test_images, test_labels):\n",
        "  _, l, acc = forward(im, label)\n",
        "  loss += l\n",
        "  num_correct += acc\n",
        "\n",
        "num_tests = len(test_images)\n",
        "print('Test Loss:', loss / num_tests)\n",
        "print('Test Accuracy:', num_correct / num_tests)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "'''\n",
        "Note: In this implementation, we assume the input is a 2d numpy array for simplicity, because that's\n",
        "how our MNIST images are stored. This works for us because we use it as the first layer in our\n",
        "network, but most CNNs have many more Conv layers. If we were building a bigger network that needed\n",
        "to use Conv3x3 multiple times, we'd have to make the input be a 3d numpy array.\n",
        "'''\n",
        "\n",
        "class Conv3x3:\n",
        "  # A Convolution layer using 3x3 filters.\n",
        "\n",
        "  def __init__(self, num_filters):\n",
        "    self.num_filters = num_filters\n",
        "\n",
        "    # filters is a 3d array with dimensions (num_filters, 3, 3)\n",
        "    # We divide by 9 to reduce the variance of our initial values\n",
        "    self.filters = np.random.randn(num_filters, 3, 3) / 9\n",
        "\n",
        "  def iterate_regions(self, image):\n",
        "    '''\n",
        "    Generates all possible 3x3 image regions using valid padding.\n",
        "    - image is a 2d numpy array.\n",
        "    '''\n",
        "    h, w = image.shape\n",
        "\n",
        "    for i in range(h - 2):\n",
        "      for j in range(w - 2):\n",
        "        im_region = image[i:(i + 3), j:(j + 3)]\n",
        "        yield im_region, i, j\n",
        "\n",
        "  def forward(self, input):\n",
        "    '''\n",
        "    Performs a forward pass of the conv layer using the given input.\n",
        "    Returns a 3d numpy array with dimensions (h, w, num_filters).\n",
        "    - input is a 2d numpy array\n",
        "    '''\n",
        "    self.last_input = input\n",
        "\n",
        "    h, w = input.shape\n",
        "    output = np.zeros((h - 2, w - 2, self.num_filters))\n",
        "\n",
        "    for im_region, i, j in self.iterate_regions(input):\n",
        "      output[i, j] = np.sum(im_region * self.filters, axis=(1, 2))\n",
        "\n",
        "    return output\n",
        "\n",
        "  def backprop(self, d_L_d_out, learn_rate):\n",
        "    '''\n",
        "    Performs a backward pass of the conv layer.\n",
        "    - d_L_d_out is the loss gradient for this layer's outputs.\n",
        "    - learn_rate is a float.\n",
        "    '''\n",
        "    d_L_d_filters = np.zeros(self.filters.shape)\n",
        "\n",
        "    for im_region, i, j in self.iterate_regions(self.last_input):\n",
        "      for f in range(self.num_filters):\n",
        "        d_L_d_filters[f] += d_L_d_out[i, j, f] * im_region\n",
        "\n",
        "    # Update filters\n",
        "    self.filters -= learn_rate * d_L_d_filters\n",
        "\n",
        "    # We aren't returning anything here since we use Conv3x3 as the first layer in our CNN.\n",
        "    # Otherwise, we'd need to return the loss gradient for this layer's inputs, just like every\n",
        "    # other layer in our CNN.\n",
        "    return None"
      ],
      "metadata": {
        "id": "2401WhYDVWDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hmRR7SCBVg5z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}